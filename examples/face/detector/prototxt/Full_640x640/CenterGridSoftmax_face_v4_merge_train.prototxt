name: "CenterGridFace_train"
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.007842999882996082
    mirror: true
    mean_value: 103.94000244140625
    mean_value: 116.77999877929688
    mean_value: 123.68000030517578
    resize_param {
      prob: 1.0
      resize_mode: WARP
      height: 640
      width: 640
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32.0
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18.0
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0.0
    }
  }
  annotated_data_param {
    batch_sampler {
      sampler {
        min_scale: 0.30000001192092896
        max_scale: 1.0
        min_aspect_ratio: 0.30000001192092896
        max_aspect_ratio: 1.0
      }
      sample_constraint {
        min_jaccard_overlap: 1.0
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.4000000059604645
        max_scale: 1.0
        min_aspect_ratio: 0.4000000059604645
        max_aspect_ratio: 1.0
      }
      sample_constraint {
        min_jaccard_overlap: 1.0
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.5
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 1.0
      }
      sample_constraint {
        min_jaccard_overlap: 1.0
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.6000000238418579
        max_scale: 1.0
        min_aspect_ratio: 0.6000000238418579
        max_aspect_ratio: 1.0
      }
      sample_constraint {
        min_jaccard_overlap: 1.0
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.699999988079071
        max_scale: 1.0
        min_aspect_ratio: 0.699999988079071
        max_aspect_ratio: 1.0
      }
      sample_constraint {
        min_jaccard_overlap: 1.0
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.800000011920929
        max_scale: 1.0
        min_aspect_ratio: 0.800000011920929
        max_aspect_ratio: 1.0
      }
      sample_constraint {
        max_jaccard_overlap: 1.0
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.8999999761581421
        max_scale: 1.0
        min_aspect_ratio: 0.8999999761581421
        max_aspect_ratio: 1.0
      }
      sample_constraint {
        max_jaccard_overlap: 1.0
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "../labelmap.prototxt"
    data_anchor_sampler {
      scale: 16
      scale: 32
      scale: 64
      scale: 128
      scale: 256
      scale: 512
      sample_constraint {
        min_object_coverage: 0.75
      }
      max_sample: 1
      max_trials: 50
    }
    yoloformat: true
    crop_type: CROP_JITTER
    has_landmarks: true
  }
  data_param {
    source: "../../../../../dataset/facedata/wider_face/lmdb/wider_face_wider_train_lm_lmdb/"
    batch_size: 12
    backend: LMDB
  }
}
layer {
  name: "conv_0"
  type: "Convolution"
  bottom: "data"
  top: "conv_0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_0_bn"
  type: "BatchNormScale"
  bottom: "conv_0"
  top: "conv_0"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_0_relu6"
  type: "ReLU6"
  bottom: "conv_0"
  top: "conv_0"
}
layer {
  name: "conv_0_0/depthwise"
  type: "Convolution"
  bottom: "conv_0"
  top: "conv_0_0/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 32
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_0_0/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_0_0/depthwise"
  top: "conv_0_0/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_0_0/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_0_0/depthwise"
  top: "conv_0_0/depthwise"
}
layer {
  name: "conv_0_0/linear"
  type: "Convolution"
  bottom: "conv_0_0/depthwise"
  top: "conv_0_0/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_0_0/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_0_0/linear"
  top: "conv_0_0/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_0_0/linear_relu6"
  type: "ReLU6"
  bottom: "conv_0_0/linear"
  top: "conv_0_0/linear"
}
layer {
  name: "conv_1_0/expand"
  type: "Convolution"
  bottom: "conv_0_0/linear"
  top: "conv_1_0/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_0/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_1_0/expand"
  top: "conv_1_0/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_1_0/expand_relu6"
  type: "ReLU6"
  bottom: "conv_1_0/expand"
  top: "conv_1_0/expand"
}
layer {
  name: "conv_1_0/depthwise"
  type: "Convolution"
  bottom: "conv_1_0/expand"
  top: "conv_1_0/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 96
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_0/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_1_0/depthwise"
  top: "conv_1_0/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_1_0/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_1_0/depthwise"
  top: "conv_1_0/depthwise"
}
layer {
  name: "conv_1_0/linear"
  type: "Convolution"
  bottom: "conv_1_0/depthwise"
  top: "conv_1_0/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_0/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_1_0/linear"
  top: "conv_1_0/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_1_1/expand"
  type: "Convolution"
  bottom: "conv_1_0/linear"
  top: "conv_1_1/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_1/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_1_1/expand"
  top: "conv_1_1/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_1_1/expand_relu6"
  type: "ReLU6"
  bottom: "conv_1_1/expand"
  top: "conv_1_1/expand"
}
layer {
  name: "conv_1_1/depthwise"
  type: "Convolution"
  bottom: "conv_1_1/expand"
  top: "conv_1_1/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 144
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_1/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_1_1/depthwise"
  top: "conv_1_1/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_1_1/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_1_1/depthwise"
  top: "conv_1_1/depthwise"
}
layer {
  name: "conv_1_1/linear"
  type: "Convolution"
  bottom: "conv_1_1/depthwise"
  top: "conv_1_1/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_1/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_1_1/linear"
  top: "conv_1_1/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_1_1"
  type: "Eltwise"
  bottom: "conv_1_0/linear"
  bottom: "conv_1_1/linear"
  top: "Res_Sum_1_1"
}
layer {
  name: "conv_1_2/expand"
  type: "Convolution"
  bottom: "Res_Sum_1_1"
  top: "conv_1_2/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_2/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_1_2/expand"
  top: "conv_1_2/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_1_2/expand_relu6"
  type: "ReLU6"
  bottom: "conv_1_2/expand"
  top: "conv_1_2/expand"
}
layer {
  name: "conv_1_2/depthwise"
  type: "Convolution"
  bottom: "conv_1_2/expand"
  top: "conv_1_2/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 144
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_2/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_1_2/depthwise"
  top: "conv_1_2/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_1_2/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_1_2/depthwise"
  top: "conv_1_2/depthwise"
}
layer {
  name: "conv_1_2/linear"
  type: "Convolution"
  bottom: "conv_1_2/depthwise"
  top: "conv_1_2/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_2/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_1_2/linear"
  top: "conv_1_2/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_1_2"
  type: "Eltwise"
  bottom: "Res_Sum_1_1"
  bottom: "conv_1_2/linear"
  top: "Res_Sum_1_2"
}
layer {
  name: "conv_2_0/expand"
  type: "Convolution"
  bottom: "Res_Sum_1_2"
  top: "conv_2_0/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_2_0/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_2_0/expand"
  top: "conv_2_0/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_2_0/expand_relu6"
  type: "ReLU6"
  bottom: "conv_2_0/expand"
  top: "conv_2_0/expand"
}
layer {
  name: "conv_2_0/depthwise"
  type: "Convolution"
  bottom: "conv_2_0/expand"
  top: "conv_2_0/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 144
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 144
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_2_0/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_2_0/depthwise"
  top: "conv_2_0/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_2_0/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_2_0/depthwise"
  top: "conv_2_0/depthwise"
}
layer {
  name: "conv_2_0/linear"
  type: "Convolution"
  bottom: "conv_2_0/depthwise"
  top: "conv_2_0/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_2_0/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_2_0/linear"
  top: "conv_2_0/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_2_1/expand"
  type: "Convolution"
  bottom: "conv_2_0/linear"
  top: "conv_2_1/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_2_1/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_2_1/expand"
  top: "conv_2_1/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_2_1/expand_relu6"
  type: "ReLU6"
  bottom: "conv_2_1/expand"
  top: "conv_2_1/expand"
}
layer {
  name: "conv_2_1/depthwise"
  type: "Convolution"
  bottom: "conv_2_1/expand"
  top: "conv_2_1/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 192
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_2_1/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_2_1/depthwise"
  top: "conv_2_1/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_2_1/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_2_1/depthwise"
  top: "conv_2_1/depthwise"
}
layer {
  name: "conv_2_1/linear"
  type: "Convolution"
  bottom: "conv_2_1/depthwise"
  top: "conv_2_1/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_2_1/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_2_1/linear"
  top: "conv_2_1/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_2_1"
  type: "Eltwise"
  bottom: "conv_2_0/linear"
  bottom: "conv_2_1/linear"
  top: "Res_Sum_2_1"
}
layer {
  name: "conv_2_2/expand"
  type: "Convolution"
  bottom: "Res_Sum_2_1"
  top: "conv_2_2/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_2_2/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_2_2/expand"
  top: "conv_2_2/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_2_2/expand_relu6"
  type: "ReLU6"
  bottom: "conv_2_2/expand"
  top: "conv_2_2/expand"
}
layer {
  name: "conv_2_2/depthwise"
  type: "Convolution"
  bottom: "conv_2_2/expand"
  top: "conv_2_2/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 192
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_2_2/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_2_2/depthwise"
  top: "conv_2_2/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_2_2/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_2_2/depthwise"
  top: "conv_2_2/depthwise"
}
layer {
  name: "conv_2_2/linear"
  type: "Convolution"
  bottom: "conv_2_2/depthwise"
  top: "conv_2_2/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_2_2/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_2_2/linear"
  top: "conv_2_2/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_2_2"
  type: "Eltwise"
  bottom: "Res_Sum_2_1"
  bottom: "conv_2_2/linear"
  top: "Res_Sum_2_2"
}
layer {
  name: "conv_3_0/expand"
  type: "Convolution"
  bottom: "Res_Sum_2_2"
  top: "conv_3_0/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_0/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_3_0/expand"
  top: "conv_3_0/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_0/expand_relu6"
  type: "ReLU6"
  bottom: "conv_3_0/expand"
  top: "conv_3_0/expand"
}
layer {
  name: "conv_3_0/depthwise"
  type: "Convolution"
  bottom: "conv_3_0/expand"
  top: "conv_3_0/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 192
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_0/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_3_0/depthwise"
  top: "conv_3_0/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_0/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_3_0/depthwise"
  top: "conv_3_0/depthwise"
}
layer {
  name: "conv_3_0/linear"
  type: "Convolution"
  bottom: "conv_3_0/depthwise"
  top: "conv_3_0/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_0/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_3_0/linear"
  top: "conv_3_0/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_1/expand"
  type: "Convolution"
  bottom: "conv_3_0/linear"
  top: "conv_3_1/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_1/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_3_1/expand"
  top: "conv_3_1/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_1/expand_relu6"
  type: "ReLU6"
  bottom: "conv_3_1/expand"
  top: "conv_3_1/expand"
}
layer {
  name: "conv_3_1/depthwise"
  type: "Convolution"
  bottom: "conv_3_1/expand"
  top: "conv_3_1/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 384
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_1/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_3_1/depthwise"
  top: "conv_3_1/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_1/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_3_1/depthwise"
  top: "conv_3_1/depthwise"
}
layer {
  name: "conv_3_1/linear"
  type: "Convolution"
  bottom: "conv_3_1/depthwise"
  top: "conv_3_1/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_1/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_3_1/linear"
  top: "conv_3_1/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_3_1"
  type: "Eltwise"
  bottom: "conv_3_0/linear"
  bottom: "conv_3_1/linear"
  top: "Res_Sum_3_1"
}
layer {
  name: "conv_3_2/expand"
  type: "Convolution"
  bottom: "Res_Sum_3_1"
  top: "conv_3_2/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_2/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_3_2/expand"
  top: "conv_3_2/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_2/expand_relu6"
  type: "ReLU6"
  bottom: "conv_3_2/expand"
  top: "conv_3_2/expand"
}
layer {
  name: "conv_3_2/depthwise"
  type: "Convolution"
  bottom: "conv_3_2/expand"
  top: "conv_3_2/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 384
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_2/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_3_2/depthwise"
  top: "conv_3_2/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_2/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_3_2/depthwise"
  top: "conv_3_2/depthwise"
}
layer {
  name: "conv_3_2/linear"
  type: "Convolution"
  bottom: "conv_3_2/depthwise"
  top: "conv_3_2/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_2/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_3_2/linear"
  top: "conv_3_2/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_3_2"
  type: "Eltwise"
  bottom: "Res_Sum_3_1"
  bottom: "conv_3_2/linear"
  top: "Res_Sum_3_2"
}
layer {
  name: "conv_3_3/expand"
  type: "Convolution"
  bottom: "Res_Sum_3_2"
  top: "conv_3_3/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_3/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_3_3/expand"
  top: "conv_3_3/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_3/expand_relu6"
  type: "ReLU6"
  bottom: "conv_3_3/expand"
  top: "conv_3_3/expand"
}
layer {
  name: "conv_3_3/depthwise"
  type: "Convolution"
  bottom: "conv_3_3/expand"
  top: "conv_3_3/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 384
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_3/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_3_3/depthwise"
  top: "conv_3_3/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_3/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_3_3/depthwise"
  top: "conv_3_3/depthwise"
}
layer {
  name: "conv_3_3/linear"
  type: "Convolution"
  bottom: "conv_3_3/depthwise"
  top: "conv_3_3/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_3/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_3_3/linear"
  top: "conv_3_3/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_3_3"
  type: "Eltwise"
  bottom: "Res_Sum_3_2"
  bottom: "conv_3_3/linear"
  top: "Res_Sum_3_3"
}
layer {
  name: "conv_3_4/expand"
  type: "Convolution"
  bottom: "Res_Sum_3_3"
  top: "conv_3_4/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_4/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_3_4/expand"
  top: "conv_3_4/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_4/expand_relu6"
  type: "ReLU6"
  bottom: "conv_3_4/expand"
  top: "conv_3_4/expand"
}
layer {
  name: "conv_3_4/depthwise"
  type: "Convolution"
  bottom: "conv_3_4/expand"
  top: "conv_3_4/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 384
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_4/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_3_4/depthwise"
  top: "conv_3_4/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_3_4/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_3_4/depthwise"
  top: "conv_3_4/depthwise"
}
layer {
  name: "conv_3_4/linear"
  type: "Convolution"
  bottom: "conv_3_4/depthwise"
  top: "conv_3_4/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_3_4/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_3_4/linear"
  top: "conv_3_4/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_3_4"
  type: "Eltwise"
  bottom: "Res_Sum_3_3"
  bottom: "conv_3_4/linear"
  top: "Res_Sum_3_4"
}
layer {
  name: "conv_4_0/expand"
  type: "Convolution"
  bottom: "Res_Sum_3_4"
  top: "conv_4_0/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_4_0/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_4_0/expand"
  top: "conv_4_0/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_4_0/expand_relu6"
  type: "ReLU6"
  bottom: "conv_4_0/expand"
  top: "conv_4_0/expand"
}
layer {
  name: "conv_4_0/depthwise"
  type: "Convolution"
  bottom: "conv_4_0/expand"
  top: "conv_4_0/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 384
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 384
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_4_0/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_4_0/depthwise"
  top: "conv_4_0/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_4_0/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_4_0/depthwise"
  top: "conv_4_0/depthwise"
}
layer {
  name: "conv_4_0/linear"
  type: "Convolution"
  bottom: "conv_4_0/depthwise"
  top: "conv_4_0/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_4_0/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_4_0/linear"
  top: "conv_4_0/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_4_1/expand"
  type: "Convolution"
  bottom: "conv_4_0/linear"
  top: "conv_4_1/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_4_1/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_4_1/expand"
  top: "conv_4_1/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_4_1/expand_relu6"
  type: "ReLU6"
  bottom: "conv_4_1/expand"
  top: "conv_4_1/expand"
}
layer {
  name: "conv_4_1/depthwise"
  type: "Convolution"
  bottom: "conv_4_1/expand"
  top: "conv_4_1/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 768
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_4_1/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_4_1/depthwise"
  top: "conv_4_1/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_4_1/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_4_1/depthwise"
  top: "conv_4_1/depthwise"
}
layer {
  name: "conv_4_1/linear"
  type: "Convolution"
  bottom: "conv_4_1/depthwise"
  top: "conv_4_1/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_4_1/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_4_1/linear"
  top: "conv_4_1/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_4_1"
  type: "Eltwise"
  bottom: "conv_4_0/linear"
  bottom: "conv_4_1/linear"
  top: "Res_Sum_4_1"
}
layer {
  name: "conv_4_2/expand"
  type: "Convolution"
  bottom: "Res_Sum_4_1"
  top: "conv_4_2/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_4_2/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_4_2/expand"
  top: "conv_4_2/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_4_2/expand_relu6"
  type: "ReLU6"
  bottom: "conv_4_2/expand"
  top: "conv_4_2/expand"
}
layer {
  name: "conv_4_2/depthwise"
  type: "Convolution"
  bottom: "conv_4_2/expand"
  top: "conv_4_2/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 768
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_4_2/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_4_2/depthwise"
  top: "conv_4_2/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_4_2/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_4_2/depthwise"
  top: "conv_4_2/depthwise"
}
layer {
  name: "conv_4_2/linear"
  type: "Convolution"
  bottom: "conv_4_2/depthwise"
  top: "conv_4_2/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_4_2/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_4_2/linear"
  top: "conv_4_2/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_4_2"
  type: "Eltwise"
  bottom: "Res_Sum_4_1"
  bottom: "conv_4_2/linear"
  top: "Res_Sum_4_2"
}
layer {
  name: "conv_5_0/expand"
  type: "Convolution"
  bottom: "Res_Sum_4_2"
  top: "conv_5_0/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_5_0/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_5_0/expand"
  top: "conv_5_0/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_5_0/expand_relu6"
  type: "ReLU6"
  bottom: "conv_5_0/expand"
  top: "conv_5_0/expand"
}
layer {
  name: "conv_5_0/depthwise"
  type: "Convolution"
  bottom: "conv_5_0/expand"
  top: "conv_5_0/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 768
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_5_0/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_5_0/depthwise"
  top: "conv_5_0/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_5_0/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_5_0/depthwise"
  top: "conv_5_0/depthwise"
}
layer {
  name: "conv_5_0/linear"
  type: "Convolution"
  bottom: "conv_5_0/depthwise"
  top: "conv_5_0/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_5_0/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_5_0/linear"
  top: "conv_5_0/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_5_1/expand"
  type: "Convolution"
  bottom: "conv_5_0/linear"
  top: "conv_5_1/expand"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_5_1/expand_bn"
  type: "BatchNormScale"
  bottom: "conv_5_1/expand"
  top: "conv_5_1/expand"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_5_1/expand_relu6"
  type: "ReLU6"
  bottom: "conv_5_1/expand"
  top: "conv_5_1/expand"
}
layer {
  name: "conv_5_1/depthwise"
  type: "Convolution"
  bottom: "conv_5_1/expand"
  top: "conv_5_1/depthwise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 768
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 768
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_5_1/depthwise_bn"
  type: "BatchNormScale"
  bottom: "conv_5_1/depthwise"
  top: "conv_5_1/depthwise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_5_1/depthwise_relu6"
  type: "ReLU6"
  bottom: "conv_5_1/depthwise"
  top: "conv_5_1/depthwise"
}
layer {
  name: "conv_5_1/linear"
  type: "Convolution"
  bottom: "conv_5_1/depthwise"
  top: "conv_5_1/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_5_1/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_5_1/linear"
  top: "conv_5_1/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Res_Sum_5_1"
  type: "Eltwise"
  bottom: "conv_5_0/linear"
  bottom: "conv_5_1/linear"
  top: "Res_Sum_5_1"
}
layer {
  name: "conv_1_project_16/DepthWise"
  type: "Convolution"
  bottom: "Res_Sum_5_1"
  top: "conv_1_project_16/DepthWise"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_project_16/DepthWise_bn"
  type: "BatchNormScale"
  bottom: "conv_1_project_16/DepthWise"
  top: "conv_1_project_16/DepthWise"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_1_project_16/DepthWise_relu6"
  type: "ReLU6"
  bottom: "conv_1_project_16/DepthWise"
  top: "conv_1_project_16/DepthWise"
}
layer {
  name: "conv_1_project_16/linear"
  type: "Convolution"
  bottom: "conv_1_project_16/DepthWise"
  top: "conv_1_project_16/linear"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv_1_project_16/linear_bn"
  type: "BatchNormScale"
  bottom: "conv_1_project_16/linear"
  top: "conv_1_project_16/linear"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "conv_1_project_16/linear_relu6"
  type: "ReLU6"
  bottom: "conv_1_project_16/linear"
  top: "conv_1_project_16/linear"
}
layer {
  name: "Deconv_Scale_Up_Stage_128_0"
  type: "Deconvolution"
  bottom: "conv_1_project_16/linear"
  top: "Deconv_Scale_Up_Stage_128_0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Deconv_Scale_Up_Stage_128_0_bn"
  type: "BatchNormScale"
  bottom: "Deconv_Scale_Up_Stage_128_0"
  top: "Deconv_Scale_Up_Stage_128_0"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "ConvFpn_128_0"
  type: "Convolution"
  bottom: "Res_Sum_5_1"
  top: "ConvFpn_128_0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "ConvFpn_128_0_bn"
  type: "BatchNormScale"
  bottom: "ConvFpn_128_0"
  top: "ConvFpn_128_0"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Resconnection_128_0_stage_128"
  type: "Eltwise"
  bottom: "Deconv_Scale_Up_Stage_128_0"
  bottom: "ConvFpn_128_0"
  top: "Resconnection_128_0_stage_128"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Resconnection_128_0_stage_128/Relu6"
  type: "ReLU6"
  bottom: "Resconnection_128_0_stage_128"
  top: "Resconnection_128_0_stage_128"
}
layer {
  name: "Det_1x1_out_128_0"
  type: "Convolution"
  bottom: "Resconnection_128_0_stage_128"
  top: "Det_1x1_out_128_0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Deconv_Scale_Up_Stage_128_1"
  type: "Deconvolution"
  bottom: "Resconnection_128_0_stage_128"
  top: "Deconv_Scale_Up_Stage_128_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Deconv_Scale_Up_Stage_128_1_bn"
  type: "BatchNormScale"
  bottom: "Deconv_Scale_Up_Stage_128_1"
  top: "Deconv_Scale_Up_Stage_128_1"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "ConvFpn_128_1"
  type: "Convolution"
  bottom: "Res_Sum_4_2"
  top: "ConvFpn_128_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "ConvFpn_128_1_bn"
  type: "BatchNormScale"
  bottom: "ConvFpn_128_1"
  top: "ConvFpn_128_1"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Resconnection_128_1_stage_128"
  type: "Eltwise"
  bottom: "Deconv_Scale_Up_Stage_128_1"
  bottom: "ConvFpn_128_1"
  top: "Resconnection_128_1_stage_128"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Resconnection_128_1_stage_128/Relu6"
  type: "ReLU6"
  bottom: "Resconnection_128_1_stage_128"
  top: "Resconnection_128_1_stage_128"
}
layer {
  name: "Det_1x1_out_128_1"
  type: "Convolution"
  bottom: "Resconnection_128_1_stage_128"
  top: "Det_1x1_out_128_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Deconv_Scale_Up_Stage_64_2"
  type: "Deconvolution"
  bottom: "Resconnection_128_1_stage_128"
  top: "Deconv_Scale_Up_Stage_64_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Deconv_Scale_Up_Stage_64_2_bn"
  type: "BatchNormScale"
  bottom: "Deconv_Scale_Up_Stage_64_2"
  top: "Deconv_Scale_Up_Stage_64_2"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "ConvFpn_64_2"
  type: "Convolution"
  bottom: "Res_Sum_3_4"
  top: "ConvFpn_64_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "ConvFpn_64_2_bn"
  type: "BatchNormScale"
  bottom: "ConvFpn_64_2"
  top: "ConvFpn_64_2"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Resconnection_64_2_stage_64"
  type: "Eltwise"
  bottom: "Deconv_Scale_Up_Stage_64_2"
  bottom: "ConvFpn_64_2"
  top: "Resconnection_64_2_stage_64"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Resconnection_64_2_stage_64/Relu6"
  type: "ReLU6"
  bottom: "Resconnection_64_2_stage_64"
  top: "Resconnection_64_2_stage_64"
}
layer {
  name: "Det_1x1_out_64_2"
  type: "Convolution"
  bottom: "Resconnection_64_2_stage_64"
  top: "Det_1x1_out_64_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Deconv_Scale_Up_Stage_32_3"
  type: "Deconvolution"
  bottom: "Resconnection_64_2_stage_64"
  top: "Deconv_Scale_Up_Stage_32_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Deconv_Scale_Up_Stage_32_3_bn"
  type: "BatchNormScale"
  bottom: "Deconv_Scale_Up_Stage_32_3"
  top: "Deconv_Scale_Up_Stage_32_3"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "ConvFpn_32_3"
  type: "Convolution"
  bottom: "Res_Sum_2_2"
  top: "ConvFpn_32_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "ConvFpn_32_3_bn"
  type: "BatchNormScale"
  bottom: "ConvFpn_32_3"
  top: "ConvFpn_32_3"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Resconnection_32_3_stage_32"
  type: "Eltwise"
  bottom: "Deconv_Scale_Up_Stage_32_3"
  bottom: "ConvFpn_32_3"
  top: "Resconnection_32_3_stage_32"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Resconnection_32_3_stage_32/Relu6"
  type: "ReLU6"
  bottom: "Resconnection_32_3_stage_32"
  top: "Resconnection_32_3_stage_32"
}
layer {
  name: "Det_1x1_out_32_3"
  type: "Convolution"
  bottom: "Resconnection_32_3_stage_32"
  top: "Det_1x1_out_32_3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Deconv_Scale_Up_Stage_24_4"
  type: "Deconvolution"
  bottom: "Resconnection_32_3_stage_32"
  top: "Deconv_Scale_Up_Stage_24_4"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Deconv_Scale_Up_Stage_24_4_bn"
  type: "BatchNormScale"
  bottom: "Deconv_Scale_Up_Stage_24_4"
  top: "Deconv_Scale_Up_Stage_24_4"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "ConvFpn_24_4"
  type: "Convolution"
  bottom: "Res_Sum_1_2"
  top: "ConvFpn_24_4"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "ConvFpn_24_4_bn"
  type: "BatchNormScale"
  bottom: "ConvFpn_24_4"
  top: "ConvFpn_24_4"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Resconnection_24_4_stage_24"
  type: "Eltwise"
  bottom: "Deconv_Scale_Up_Stage_24_4"
  bottom: "ConvFpn_24_4"
  top: "Resconnection_24_4_stage_24"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Resconnection_24_4_stage_24/Relu6"
  type: "ReLU6"
  bottom: "Resconnection_24_4_stage_24"
  top: "Resconnection_24_4_stage_24"
}
layer {
  name: "Det_1x1_out_24_4"
  type: "Convolution"
  bottom: "Resconnection_24_4_stage_24"
  top: "Det_1x1_out_24_4"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "CenterGridLoss_0"
  type: "CenterGridLoss"
  bottom: "Det_1x1_out_128_0"
  bottom: "label"
  top: "CenterGridLoss_0"
  loss_weight: 1.0
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  center_object_loss_param {
    num_class: 2
    share_location: true
    loc_weight: 1.0
    bias_scale: 475.0
    bias_num: 1
    net_width: 640
    net_height: 640
    low_bbox_scale: 320
    up_bbox_scale: 630
    class_type: SOFTMAX
    has_lm: true
  }
}
layer {
  name: "CenterGridLoss_1"
  type: "CenterGridLoss"
  bottom: "Det_1x1_out_128_1"
  bottom: "label"
  top: "CenterGridLoss_1"
  loss_weight: 1.0
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  center_object_loss_param {
    num_class: 2
    share_location: true
    loc_weight: 1.0
    bias_scale: 240.0
    bias_num: 1
    net_width: 640
    net_height: 640
    low_bbox_scale: 160
    up_bbox_scale: 320
    class_type: SOFTMAX
    has_lm: true
  }
}
layer {
  name: "CenterGridLoss_2"
  type: "CenterGridLoss"
  bottom: "Det_1x1_out_64_2"
  bottom: "label"
  top: "CenterGridLoss_2"
  loss_weight: 0.800000011920929
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  center_object_loss_param {
    num_class: 2
    share_location: true
    loc_weight: 1.0
    bias_scale: 120.0
    bias_num: 1
    net_width: 640
    net_height: 640
    low_bbox_scale: 80
    up_bbox_scale: 160
    class_type: SOFTMAX
    has_lm: true
  }
}
layer {
  name: "CenterGridLoss_3"
  type: "CenterGridLoss"
  bottom: "Det_1x1_out_32_3"
  bottom: "label"
  top: "CenterGridLoss_3"
  loss_weight: 0.800000011920929
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  center_object_loss_param {
    num_class: 2
    share_location: true
    loc_weight: 1.0
    bias_scale: 60.0
    bias_num: 1
    net_width: 640
    net_height: 640
    low_bbox_scale: 40
    up_bbox_scale: 80
    class_type: SOFTMAX
    has_lm: true
  }
}
layer {
  name: "CenterGridLoss_4"
  type: "CenterGridLoss"
  bottom: "Det_1x1_out_24_4"
  bottom: "label"
  top: "CenterGridLoss_4"
  loss_weight: 0.5
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  center_object_loss_param {
    num_class: 2
    share_location: true
    loc_weight: 1.0
    bias_scale: 23.0
    bias_num: 1
    net_width: 640
    net_height: 640
    low_bbox_scale: 6
    up_bbox_scale: 40
    class_type: SOFTMAX
    has_lm: true
  }
}

